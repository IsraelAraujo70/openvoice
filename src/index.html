<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OpenVoice</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    html, body {
      width: 100%;
      height: 100%;
      background: transparent;
      overflow: hidden;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    }

    .container {
      width: 100%;
      height: 100%;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      background: rgba(0, 0, 0, 0.9);
      border-radius: 16px;
      border: 2px solid #333;
      padding: 20px;
    }

    .container.recording {
      border-color: #ff4444;
      animation: pulse-border 1s ease-in-out infinite;
    }

    .container.processing {
      border-color: #ffaa00;
    }

    .container.success {
      border-color: #00ff00;
    }

    .container.error {
      border-color: #ff4444;
    }

    @keyframes pulse-border {
      0%, 100% { border-color: #ff4444; }
      50% { border-color: #aa0000; }
    }

    .icon {
      font-size: 48px;
      margin-bottom: 10px;
    }

    .status {
      color: white;
      font-size: 16px;
      font-weight: 500;
      text-align: center;
    }

    .hint {
      color: #888;
      font-size: 12px;
      margin-top: 8px;
      text-align: center;
    }

    .recording-dot {
      display: inline-block;
      width: 12px;
      height: 12px;
      background: #ff0000;
      border-radius: 50%;
      margin-right: 8px;
      animation: blink 1s ease-in-out infinite;
    }

    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.3; }
    }

    .transcription-preview {
      color: #aaa;
      font-size: 11px;
      margin-top: 8px;
      max-width: 100%;
      overflow: hidden;
      text-overflow: ellipsis;
      white-space: nowrap;
    }
  </style>
</head>
<body>
  <div id="container" class="container">
    <div class="icon" id="icon">üéôÔ∏è</div>
    <div class="status" id="status">Ready</div>
    <div class="hint" id="hint">Press shortcut to record</div>
    <div class="transcription-preview" id="preview"></div>
  </div>

  <script>
    const { invoke } = window.__TAURI__.core;
    const { listen } = window.__TAURI__.event;
    const { getCurrentWindow } = window.__TAURI__.window;

    const container = document.getElementById('container');
    const icon = document.getElementById('icon');
    const status = document.getElementById('status');
    const hint = document.getElementById('hint');
    const preview = document.getElementById('preview');

    let currentShortcut = 'Ctrl+Shift+V';
    const appWindow = getCurrentWindow();

    // Load config to get shortcut
    async function loadConfig() {
      try {
        const config = await invoke('load_config');
        currentShortcut = config.shortcut || 'Ctrl+Shift+V';
        if (config.audio_device) {
          await invoke('set_audio_device', { deviceName: config.audio_device });
        }
        console.log('Config loaded, shortcut:', currentShortcut);
      } catch (e) {
        console.error('Failed to load config:', e);
      }
    }

    function updateUI(state, message, hintText = '', previewText = '') {
      container.className = 'container ' + state;
      status.innerHTML = message;
      hint.textContent = hintText;
      preview.textContent = previewText;
      
      switch(state) {
        case 'recording':
          icon.textContent = 'üî¥';
          break;
        case 'processing':
          icon.textContent = '‚è≥';
          break;
        case 'success':
          icon.textContent = '‚úÖ';
          break;
        case 'error':
          icon.textContent = '‚ùå';
          break;
        default:
          icon.textContent = 'üéôÔ∏è';
      }
    }

    // Listen for backend events
    listen('recording-started', () => {
      console.log('Recording started event received');
      updateUI('recording', '<span class="recording-dot"></span>Recording...', 'Press Escape to stop');
    });

    listen('recording-stopped', () => {
      console.log('Recording stopped event received');
      updateUI('processing', 'Processing...', 'Stopping recording...');
    });

    listen('transcription-started', () => {
      console.log('Transcription started event received');
      updateUI('processing', 'Transcribing...', 'Sending to AI...');
    });

    listen('transcription-complete', (event) => {
      console.log('Transcription complete:', event.payload);
      const text = event.payload;
      const previewText = text.length > 60 ? text.substring(0, 60) + '...' : text;
      updateUI('success', 'Copied to clipboard!', '', previewText);
    });

    listen('transcription-error', (event) => {
      console.error('Transcription error:', event.payload);
      updateUI('error', 'Error', event.payload.substring(0, 50));
    });

    // Listen for config updates
    listen('config-updated', async () => {
      console.log('Config updated');
      await loadConfig();
    });

    // Initialize
    loadConfig();
    console.log('OpenVoice UI initialized');
  </script>
</body>
</html>
